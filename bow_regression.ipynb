{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38bc3d4d-9fe1-48bc-8484-3eb2094ccc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdc16677-5885-4dcb-92f0-b62560f46b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "train_dir = \"aclImdb_v1/aclImdb/train\"\n",
    "test_dir = \"aclImdb_v1/aclImdb/test\"\n",
    "\n",
    "# Read and preprocess the movie reviews\n",
    "def read_reviews(directory):\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        for filename in os.listdir(label_dir):\n",
    "            with open(os.path.join(label_dir, filename), \"r\") as file:\n",
    "                try:\n",
    "                    review = file.read()\n",
    "                except UnicodeDecodeError:\n",
    "                    with open(os.path.join(label_dir, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "                        review = file.read()\n",
    "                rating = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "                rating = (rating - 1) / 9.0\n",
    "                reviews.append(review)\n",
    "                ratings.append(rating)\n",
    "    return reviews, ratings\n",
    "\n",
    "# Read training and testing data\n",
    "train_reviews, train_ratings = read_reviews(train_dir)\n",
    "test_reviews, test_ratings = read_reviews(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9188c1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n",
      "review:  Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn't really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I'd have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.\n",
      "rating:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#print an example\n",
    "print(\"Example\")\n",
    "print(\"review: \", train_reviews[0])\n",
    "print(\"rating: \", train_ratings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e113f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59f589",
   "metadata": {},
   "source": [
    "### Baseline Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecd17e75-c7f4-4091-9071-43ffe9cd3bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# Create bag of words representation\n",
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(train_reviews)\n",
    "test_features = vectorizer.transform(test_reviews)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(train_features, train_ratings)\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce3d7ff-2fe3-48cd-b170-29f75d9506d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 0.4387218480281554\n"
     ]
    }
   ],
   "source": [
    "# Function to predict the rating of a new review\n",
    "def predict_rating(review_text):\n",
    "    # Preprocess the review text\n",
    "    review_features = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_rating = model.predict(review_features)\n",
    "    \n",
    "    return predicted_rating[0]\n",
    "\n",
    "# Example usage\n",
    "new_review = \"This film powerfully demonstrates the struggle of two women in love in a culture so deeply entrenched in ritual and tradition. All this against a backdrop of an India which itself is struggling for freedom from these same values. This film is both political and personal and never too preachy or idealistic on either front. It is easy to see why 'Fire' has caused riots in India, but tragic nonetheless. A true film such as this one deserves to be seen by all people of the world, not just privileged westerners.\"\n",
    "predicted_rating = predict_rating(new_review)\n",
    "print(\"Predicted Rating:\", predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6060da3",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc1054e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary (i.e. the dimension of the data): 74849\n",
      "Size of the training data: 25000\n",
      "\n",
      "top 20 most important tokens, with their coefficients: \n",
      "evilest : -0.7773204948059027\n",
      "reccommend : 0.659615112344284\n",
      "unexpecting : 0.6172886394607975\n",
      "labeling : -0.5713097194205504\n",
      "abductions : -0.562729100747804\n",
      "chungking : -0.5598040681684273\n",
      "damnit : 0.5401431725143944\n",
      "raimy : 0.5271947442153081\n",
      "patterson : -0.5189534712902111\n",
      "sharpen : -0.5123163670584275\n",
      "extremelly : -0.5118941384046103\n",
      "slovenian : 0.500947631289223\n",
      "octress : -0.49975323630543117\n",
      "ailing : 0.49851396794000563\n",
      "corncobs : -0.49241025557615314\n",
      "overstatement : 0.4784211466781818\n",
      "blasphemous : -0.4756101672931148\n",
      "architectural : 0.46881094901003756\n",
      "pota : -0.4659927461345996\n",
      "reeling : 0.460805519632763\n",
      "\n",
      "bottom 20 least important tokens, with their coefficients: \n",
      "coselli : -1.1911651335721926e-05\n",
      "delarua : -1.1911651335721926e-05\n",
      "emiliano : -1.1911651335721926e-05\n",
      "esperando : -1.1911651335721926e-05\n",
      "menen : -1.1911651335721926e-05\n",
      "mesias : -1.1911651335721926e-05\n",
      "partido : -1.1911651335721926e-05\n",
      "petrielli : -1.1911651335721926e-05\n",
      "pineyro : -1.1911651335721926e-05\n",
      "binder : -1.1738516122637232e-05\n",
      "wangles : 1.1590035713747873e-05\n",
      "gooooooodddd : -1.1364384911803685e-05\n",
      "phenomenal : 1.0246720122381647e-05\n",
      "expeditions : -1.0027458599362272e-05\n",
      "filmic : 7.4620330049930874e-06\n",
      "excess : -3.1771044085532145e-06\n",
      "misunderstands : -2.8788628697810063e-06\n",
      "confetti : -2.7593915260398476e-06\n",
      "gang : 1.3248880540601384e-06\n",
      "walgreens : -8.382813351306335e-08\n"
     ]
    }
   ],
   "source": [
    "top_k = 20\n",
    "bottom_k = 20\n",
    "\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Get the whole vocabulary\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "print(f'Size of the vocabulary (i.e. the dimension of the data): {len(tokens)}')\n",
    "print(f'Size of the training data: {len(train_reviews)}\\n')\n",
    "\n",
    "# Pick the most and the least important tokens\n",
    "coeff_tokens = list(zip(coefficients, tokens))\n",
    "sorted_coeff_tokens = sorted(coeff_tokens, key=lambda x: np.abs(x[0]), reverse=True)\n",
    "print(f'top {top_k} most important tokens, with their coefficients: ')\n",
    "for coef, token in sorted_coeff_tokens[:top_k]:\n",
    "    print(f'{token} : {coef}')\n",
    "print()\n",
    "print(f'bottom {bottom_k} least important tokens, with their coefficients: ')\n",
    "for coef, token in sorted_coeff_tokens[-bottom_k:]:\n",
    "    print(f'{token} : {coef}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4901a",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c89e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.16715439239019775\n",
      "Mean Absolute Error: 0.30340951814718525\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing set\n",
    "predictions = model.predict(test_features)\n",
    "predictions = np.clip(predictions, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(test_ratings, predictions)\n",
    "mae = mean_absolute_error(test_ratings, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c72f2f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted negative reviews</th>\n",
       "      <th>predicted positive reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual negative reviews</th>\n",
       "      <td>8702</td>\n",
       "      <td>3798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual positive reviews</th>\n",
       "      <td>3885</td>\n",
       "      <td>8615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted negative reviews  \\\n",
       "actual negative reviews                        8702   \n",
       "actual positive reviews                        3885   \n",
       "\n",
       "                         predicted positive reviews  \n",
       "actual negative reviews                        3798  \n",
       "actual positive reviews                        8615  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify reviews as 'positive' (1) or 'negative' (0)\n",
    "binary_predictions = np.where(predictions < 0.5, 0, 1)\n",
    "binary_test_ratings = np.where(np.array(test_ratings) < 0.5, 0, 1)\n",
    "\n",
    "conf_matrix = confusion_matrix(binary_test_ratings, binary_predictions)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, \n",
    "                      index = [ 'actual negative reviews',  'actual positive reviews'], \n",
    "                      columns = [ 'predicted negative reviews',  'predicted positive reviews'] )\n",
    "conf_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e1d66d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6940304519455409\n",
      "Recall:  0.6892\n",
      "F1 score: 0.6916067916348895\n"
     ]
    }
   ],
   "source": [
    "tp = conf_matrix[1, 1]  # True Positives\n",
    "fp = conf_matrix[0, 1]  # False Positives\n",
    "fn = conf_matrix[1, 0]  # False Negatives\n",
    "tn = conf_matrix[0, 0]  # True Negatives\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1 score:', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dededdd2",
   "metadata": {},
   "source": [
    "### Bag of Words Model removing fill words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d7d1560-525b-4757-88db-6a5d3a25645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine fill words found during dataset analysis with default English stop words\n",
    "fill_words = ['the', 'and', 'of', 'to', 'is', 'br', 'it', 'in', 'this', 'that', 'was', 'as', \n",
    "              'for', 'with', 'movie', 'but', 'film', 'you', 'on', 'he', 'are', 'his', 'have',\n",
    "              'be', 'one', 'at', 'they', 'by', 'an', 'who', 'so', 'from', 'there', 'her', 'or', \n",
    "              'about', 'out', 'if', 'has', 'what', 'some', 'can', 'she', 'when', 'even', 'my', \n",
    "              'would', 'which', 'story', 'see', 'their', 'had', 'we', 'were', 'me', 'than', \n",
    "              'much', 'get', 'been', 'people', 'will', 'do', 'other', 'also', 'up', 'into', 'first',\n",
    "              'all', 'no', 'just', 'how', 'because', 'then']\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(fill_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e6a4ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# Create bag of words representation\n",
    "vectorizer = CountVectorizer(stop_words = stop_words)\n",
    "train_features = vectorizer.fit_transform(train_reviews)\n",
    "test_features = vectorizer.transform(test_reviews)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(train_features, train_ratings)\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79c06cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.18345109386501124\n",
      "Mean Absolute Error: 0.31853475109780754\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set and clip to [0, 1]\n",
    "predictions = model.predict(test_features)\n",
    "predictions = np.clip(predictions, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(test_ratings, predictions)\n",
    "mae = mean_absolute_error(test_ratings, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "860faf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 0.23746848485294475\n"
     ]
    }
   ],
   "source": [
    "# Function to predict the rating of a new review\n",
    "def predict_rating(review_text):\n",
    "    # Preprocess the review text\n",
    "    review_features = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_rating = model.predict(review_features)\n",
    "    \n",
    "    return predicted_rating[0]\n",
    "\n",
    "# Example usage\n",
    "new_review = \"This film powerfully demonstrates the struggle of two women in love in a culture so deeply entrenched in ritual and tradition. All this against a backdrop of an India which itself is struggling for freedom from these same values. This film is both political and personal and never too preachy or idealistic on either front. It is easy to see why 'Fire' has caused riots in India, but tragic nonetheless. A true film such as this one deserves to be seen by all people of the world, not just privileged westerners.\"\n",
    "predicted_rating = predict_rating(new_review)\n",
    "print(\"Predicted Rating:\", predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f8b3e",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f6eac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.18345109386501124\n",
      "Mean Absolute Error: 0.31853475109780754\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing set\n",
    "predictions = model.predict(test_features)\n",
    "predictions = np.clip(predictions, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(test_ratings, predictions)\n",
    "mae = mean_absolute_error(test_ratings, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e88d27e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted negative reviews</th>\n",
       "      <th>predicted positive reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual negative reviews</th>\n",
       "      <td>8440</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual positive reviews</th>\n",
       "      <td>4185</td>\n",
       "      <td>8315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted negative reviews  \\\n",
       "actual negative reviews                        8440   \n",
       "actual positive reviews                        4185   \n",
       "\n",
       "                         predicted positive reviews  \n",
       "actual negative reviews                        4060  \n",
       "actual positive reviews                        8315  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify reviews as 'positive' (1) or 'negative' (0)\n",
    "binary_predictions = np.where(predictions < 0.5, 0, 1)\n",
    "binary_test_ratings = np.where(np.array(test_ratings) < 0.5, 0, 1)\n",
    "\n",
    "conf_matrix = confusion_matrix(binary_test_ratings, binary_predictions)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, \n",
    "                      index = [ 'actual negative reviews',  'actual positive reviews'], \n",
    "                      columns = [ 'predicted negative reviews',  'predicted positive reviews'] )\n",
    "conf_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0479ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6719191919191919\n",
      "Recall:  0.6652\n",
      "F1 score: 0.6685427135678391\n"
     ]
    }
   ],
   "source": [
    "tp = conf_matrix[1, 1]  # True Positives\n",
    "fp = conf_matrix[0, 1]  # False Positives\n",
    "fn = conf_matrix[1, 0]  # False Negatives\n",
    "tn = conf_matrix[0, 0]  # True Negatives\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1 score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299faecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
